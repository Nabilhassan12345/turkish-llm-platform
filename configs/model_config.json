{
  "name": "Turkish LLM with Sector-Specific Adapters",
  "description": "Advanced Turkish Large Language Model with 22 sector-specific adapters, voice interaction, and optimized inference",
  "author": "Turkish AI Consortium",
  "version": "2.0.0",
  "license": "MIT",
  "language": "tr",
  "created_at": "2024-01-20T10:00:00Z",
  "updated_at": "2024-01-20T10:00:00Z",
  
  "supported_sectors": [
    "finance_banking",
    "healthcare",
    "education",
    "media_publishing",
    "legal",
    "public_administration",
    "manufacturing",
    "asset_tracking",
    "insurance",
    "tourism_hospitality",
    "ecommerce",
    "telecommunications",
    "real_estate",
    "logistics",
    "agriculture",
    "energy",
    "construction",
    "automotive",
    "retail",
    "consulting",
    "technology",
    "entertainment"
  ],
  
  "model_architecture": {
    "base_model": "meta-llama/Llama-2-8b-hf",
    "model_type": "llama",
    "architecture": "LlamaForCausalLM with MoE routing",
    "parameters": "8B",
    "experts": 22,
    "active_experts_per_token": 2,
    "context_length": 4096,
    "max_position_embeddings": 4096,
    "vocab_size": 32000,
    "hidden_size": 4096,
    "intermediate_size": 11008,
    "num_hidden_layers": 32,
    "num_attention_heads": 32,
    "num_key_value_heads": 32,
    "rope_theta": 10000.0,
    "torch_dtype": "bfloat16",
    "quantization": "4-bit QLoRA",
    "pruning": "structured pruning"
  },
  
  "tokenizer": {
    "name": "meta-llama/Llama-2-8b-hf",
    "padding_side": "left",
    "truncation_side": "left",
    "add_eos_token": true,
    "add_bos_token": true,
    "clean_up_tokenization_spaces": false,
    "model_max_length": 4096,
    "turkish_special_tokens": {
      "ğ": "<turkish_g>",
      "ü": "<turkish_u>",
      "ş": "<turkish_s>",
      "ı": "<turkish_i>",
      "ö": "<turkish_o>",
      "ç": "<turkish_c>"
    }
  },
  
  "training_config": {
    "method": "qlora",
    "dataset_size": "100K+ Turkish business dialogues",
    "training_hours": "72+ hours on RTX 4060",
    "fine_tuning_method": "QLoRA + Sector-Specific Adapters",
    
    "quantization": {
      "load_in_4bit": true,
      "bnb_4bit_use_double_quant": true,
      "bnb_4bit_quant_type": "nf4",
      "bnb_4bit_compute_dtype": "bfloat16"
    },
    
    "lora": {
      "r": 64,
      "lora_alpha": 16,
      "target_modules": [
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "gate_proj",
        "up_proj",
        "down_proj"
      ],
      "lora_dropout": 0.1,
      "bias": "none",
      "task_type": "CAUSAL_LM"
    },
    
    "hyperparameters": {
      "optimizer": "paged_adamw_32bit",
      "learning_rate": 2e-4,
      "num_train_epochs": 3,
      "per_device_train_batch_size": 4,
      "per_device_eval_batch_size": 4,
      "gradient_accumulation_steps": 8,
      "warmup_steps": 100,
      "max_steps": -1,
      "weight_decay": 0.01,
      "logging_steps": 10,
      "save_steps": 500,
      "eval_steps": 500,
      "save_total_limit": 3,
      "load_best_model_at_end": true,
      "metric_for_best_model": "eval_loss",
      "greater_is_better": false,
      "dataloader_num_workers": 4,
      "remove_unused_columns": false,
      "lr_scheduler_type": "cosine",
      "max_grad_norm": 0.3,
      "group_by_length": true,
      "ddp_find_unused_parameters": false
    },
    
    "data": {
      "max_seq_length": 2048,
      "dataset_text_field": "text",
      "packing": false,
      "dataset_num_proc": 4,
      "turkish_data_ratio": 0.8,
      "english_data_ratio": 0.2,
      "validation_split": 0.1
    }
  },
  
  "inference_config": {
    "max_new_tokens": 512,
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 50,
    "repetition_penalty": 1.1,
    "do_sample": true,
    "pad_token_id": 0,
    "eos_token_id": 2,
    "use_cache": true,
    "early_stopping": true,
    "num_beams": 1,
    "length_penalty": 1.0
  },
  
  "sector_routing": {
    "enabled": true,
    "routing_method": "mixture_of_experts",
    "default_sector": "technology",
    "confidence_threshold": 0.7,
    "max_sectors": 3,
    "fallback_sector": "technology",
    
    "sector_adapters": {
      "technology": {
        "adapter_path": "adapters/technology",
        "specialization": "Teknoloji, yazılım, donanım, AI/ML konuları",
        "keywords": ["teknoloji", "yazılım", "donanım", "AI", "makine öğrenmesi", "veri bilimi", "programlama"]
      },
      "healthcare": {
        "adapter_path": "adapters/healthcare",
        "specialization": "Sağlık, tıp, ilaç, tedavi konuları",
        "keywords": ["sağlık", "tıp", "hastalık", "tedavi", "ilaç", "doktor", "hastane"]
      },
      "education": {
        "adapter_path": "adapters/education",
        "specialization": "Eğitim, öğretim, akademik konular",
        "keywords": ["eğitim", "öğretim", "okul", "üniversite", "ders", "öğrenci", "öğretmen"]
      },
      "finance_banking": {
        "adapter_path": "adapters/finance_banking",
        "specialization": "Finans, bankacılık, yatırım, ekonomi",
        "keywords": ["finans", "banka", "yatırım", "ekonomi", "para", "borsa", "kredi"]
      },
      "legal": {
        "adapter_path": "adapters/legal",
        "specialization": "Hukuk, kanun, yasal konular",
        "keywords": ["hukuk", "kanun", "yasal", "mahkeme", "avukat", "dava", "mevzuat"]
      }
    }
  },
  
  "performance_metrics": {
    "inference_latency": "<150ms",
    "throughput": "120+ RPS",
    "accuracy": "90%+ on Turkish business tasks",
    "memory_usage": "8GB VRAM",
    "cpu_usage": "<25%",
    "gpu_utilization": ">80%"
  },
  
  "hardware_requirements": {
    "gpu": {
      "required": true,
      "min_vram_gb": 8,
      "recommended_vram_gb": 16,
      "cuda_version": "11.8+",
      "compute_capability": "7.5+",
      "mixed_precision": "bf16"
    },
    "cpu": {
      "min_cores": 8,
      "recommended_cores": 16,
      "min_ram_gb": 16,
      "recommended_ram_gb": 32
    },
    "storage": {
      "min_free_space_gb": 50,
      "recommended_free_space_gb": 100,
      "ssd_recommended": true
    }
  },
  
  "deployment": {
    "environment": "production",
    "container_image": "turkish-ai-agent:v2.0",
    
    "api_endpoints": [
      "/infer",
      "/classify",
      "/health",
      "/sectors",
      "/adapters",
      "/metrics"
    ],
    
    "api_config": {
      "host": "0.0.0.0",
      "http_port": 8000,
      "workers": 1,
      "timeout": 300,
      "max_requests": 1000,
      "cors_enabled": true,
      "cors_origins": ["*"]
    },
    
    "voice_config": {
      "websocket_port": 8765,
      "audio_sample_rate": 16000,
      "audio_channels": 1,
      "chunk_size": 1024,
      "stt_model": "openai/whisper-base",
      "tts_voice": "tr-TR-EmelNeural",
      "max_audio_duration": 30
    },
    
    "docker_config": {
      "base_image": "nvidia/cuda:11.8-devel-ubuntu22.04",
      "python_version": "3.10",
      "expose_ports": [8000, 8765],
      "volumes": [
        "./models:/app/models",
        "./adapters:/app/adapters",
        "./logs:/app/logs",
        "./configs:/app/configs"
      ],
      "environment_variables": {
        "CUDA_VISIBLE_DEVICES": "0",
        "TRANSFORMERS_CACHE": "/app/cache",
        "HF_HOME": "/app/cache"
      }
    }
  },
  
  "monitoring": {
    "enabled": true,
    "metrics": {
      "gpu_utilization": true,
      "memory_usage": true,
      "inference_latency": true,
      "throughput": true,
      "error_rate": true,
      "sector_distribution": true,
      "voice_processing_time": true
    },
    "logging": {
      "level": "INFO",
      "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
      "file": "logs/turkish_llm.log",
      "max_file_size_mb": 100,
      "backup_count": 5
    },
    "alerts": {
      "high_latency_threshold_ms": 500,
      "high_error_rate_threshold": 0.05,
      "low_gpu_utilization_threshold": 0.3
    }
  },
  
  "contact": {
    "email": "info@turkish-ai.org",
    "website": "https://turkish-ai.org",
    "github": "https://github.com/turkish-ai/turkish-llm",
    "documentation": "https://docs.turkish-ai.org"
  },
  
  "acknowledgments": [
    "Meta AI for Llama-2 base model",
    "Hugging Face for transformers library",
    "Microsoft for QLoRA implementation",
    "Turkish business community for domain expertise",
    "Open source community for tools and libraries",
    "NVIDIA for CUDA optimization support"
  ]
}
