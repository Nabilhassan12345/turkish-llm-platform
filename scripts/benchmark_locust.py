#!/usr/bin/env python3
"""
Locust load testing script for Turkish LLM inference benchmarking.
Bu script, LLM sisteminin Ã¶lÃ§eklenebilirliÄŸini ve performansÄ±nÄ± farklÄ± yÃ¼k
desenleri ve sektÃ¶re Ã¶zel sorgularla test eder.
"""

import time
import json
import random
import logging
from typing import Dict, List, Optional
from dataclasses import dataclass
from locust import HttpUser, task, between, events
import numpy as np
from services.router import SectorRouter
from collections import defaultdict
import psutil
import GPUtil
import os
from collections import Counter

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class BenchmarkConfig:
    """Benchmark parametreleri iÃ§in yapÄ±landÄ±rma."""

    target_rps: int = 100  # Hedef saniye baÅŸÄ±na istek
    latency_threshold_ms: int = 200  # Gecikme eÅŸiÄŸi (ms)
    max_concurrent_users: int = 200  # Maksimum eÅŸzamanlÄ± kullanÄ±cÄ±
    test_duration_seconds: int = 600  # Test sÃ¼resi (10 dakika)
    warmup_seconds: int = 60  # IsÄ±nma sÃ¼resi
    sector_weights: Dict[str, float] = None  # SektÃ¶r aÄŸÄ±rlÄ±klarÄ±


class TurkishLLMUser(HttpUser):
    """
    TÃ¼rk LLM Ã§Ä±karÄ±m performansÄ±nÄ± test etmek iÃ§in Locust kullanÄ±cÄ± sÄ±nÄ±fÄ±.
    """

    wait_time = between(0.5, 2)  # Ä°stekler arasÄ± 0.5-2 saniye bekle

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.router = SectorRouter()
        self.sector_queries = self._load_sector_queries()
        self.benchmark_metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "latencies": [],
            "sector_distribution": defaultdict(int),
            "error_types": defaultdict(int),
            "response_sizes": [],
        }

        # SektÃ¶r aÄŸÄ±rlÄ±klarÄ± (gerÃ§ek dÃ¼nya kullanÄ±m desenlerine gÃ¶re)
        self.sector_weights = {
            "finance_banking": 0.25,  # %25 - En yÃ¼ksek kullanÄ±m
            "healthcare": 0.20,  # %20
            "education": 0.15,  # %15
            "ecommerce": 0.12,  # %12
            "public_administration": 0.10,  # %10
            "legal": 0.08,  # %8
            "manufacturing": 0.05,  # %5
            "tourism_hospitality": 0.03,  # %3
            "energy": 0.02,  # %2
        }

    def _load_sector_queries(self) -> Dict[str, List[str]]:
        """SektÃ¶re Ã¶zel test sorgularÄ±nÄ± yÃ¼kle."""
        return {
            "finance_banking": [
                "Banka kredisi almak istiyorum, faiz oranlarÄ± nedir?",
                "DÃ¶viz kuru tahminleri nasÄ±l yapÄ±lÄ±r?",
                "YatÄ±rÄ±m portfÃ¶yÃ¼mÃ¼ nasÄ±l Ã§eÅŸitlendirebilirim?",
                "Sigorta poliÃ§esi seÃ§erken nelere dikkat etmeliyim?",
                "Borsa analizi iÃ§in hangi gÃ¶stergeleri takip etmeliyim?",
                "Kredi kartÄ± limitimi nasÄ±l artÄ±rabilirim?",
                "Mevduat hesabÄ± aÃ§mak iÃ§in hangi belgeler gerekli?",
                "Fon yatÄ±rÄ±mÄ± yapmak istiyorum, risk seviyeleri nelerdir?",
            ],
            "healthcare": [
                "Hastane randevusu almak istiyorum, hangi doktorlar mÃ¼sait?",
                "Bu ilacÄ±n yan etkileri nelerdir?",
                "SaÄŸlÄ±k sigortasÄ± kapsamÄ±nda hangi tedaviler var?",
                "Doktor muayenesi Ã¶ncesi nasÄ±l hazÄ±rlanmalÄ±yÄ±m?",
                "Eczane Ã§alÄ±ÅŸma saatleri nedir?",
                "Acil servis nerede bulunuyor?",
                "Laboratuvar sonuÃ§larÄ±m ne zaman hazÄ±r olur?",
                "Hangi aÅŸÄ±larÄ± olmam gerekiyor?",
            ],
            "education": [
                "Ãœniversite sÄ±navÄ±na hazÄ±rlanÄ±yorum, hangi kurslar Ã¶nerilir?",
                "Online eÄŸitim platformlarÄ± hangileri?",
                "Ã–ÄŸretmenlik sertifikasÄ± nasÄ±l alÄ±nÄ±r?",
                "YabancÄ± dil Ã¶ÄŸrenmek iÃ§in en iyi yÃ¶ntemler neler?",
                "SÄ±nav stresiyle nasÄ±l baÅŸa Ã§Ä±kabilirim?",
                "Burs baÅŸvurusu iÃ§in son tarih ne zaman?",
                "Hangi bÃ¶lÃ¼mlerde iÅŸ imkanÄ± daha fazla?",
                "Yaz okulu programlarÄ± nelerdir?",
            ],
            "ecommerce": [
                "ÃœrÃ¼n iadesi nasÄ±l yapÄ±lÄ±r?",
                "Kargo takip numarasÄ± nerede bulunur?",
                "Ã–deme seÃ§enekleri nelerdir?",
                "ÃœrÃ¼n garantisi ne kadar sÃ¼rer?",
                "Stok durumu nasÄ±l kontrol edilir?",
                "Ä°ndirim kuponlarÄ± nasÄ±l kullanÄ±lÄ±r?",
                "MÃ¼ÅŸteri hizmetleri ile nasÄ±l iletiÅŸime geÃ§ebilirim?",
                "ÃœrÃ¼n karÅŸÄ±laÅŸtÄ±rmasÄ± nasÄ±l yapÄ±lÄ±r?",
            ],
            "public_administration": [
                "Kimlik kartÄ± yenileme iÅŸlemi nasÄ±l yapÄ±lÄ±r?",
                "Pasaport baÅŸvurusu iÃ§in hangi belgeler gerekli?",
                "Vergi Ã¶demeleri ne zaman yapÄ±lmalÄ±?",
                "Belediye hizmetleri nelerdir?",
                "Sosyal gÃ¼venlik baÅŸvurusu nasÄ±l yapÄ±lÄ±r?",
                "Askerlik iÅŸlemleri nerede yapÄ±lÄ±r?",
                "Tapu iÅŸlemleri iÃ§in randevu nasÄ±l alÄ±nÄ±r?",
                "Ä°ÅŸsizlik maaÅŸÄ± baÅŸvurusu nasÄ±l yapÄ±lÄ±r?",
            ],
            "legal": [
                "Avukat Ã¼cretleri nasÄ±l belirlenir?",
                "Dava sÃ¼reci ne kadar sÃ¼rer?",
                "Hukuki danÄ±ÅŸmanlÄ±k Ã¼creti nedir?",
                "SÃ¶zleÅŸme hazÄ±rlama maliyeti nedir?",
                "Noter iÅŸlemleri nelerdir?",
                "Aile hukuku konularÄ±nda hangi haklarÄ±m var?",
                "Ä°ÅŸ hukuku kapsamÄ±nda neler yapabilirim?",
                "Ceza hukuku sÃ¼reÃ§leri nasÄ±l iÅŸler?",
            ],
            "manufacturing": [
                "Fabrikada Ã¼retim sÃ¼reÃ§lerini optimize etmek istiyorum",
                "Kalite kontrol sÃ¼reÃ§leri nasÄ±l iyileÅŸtirilir?",
                "Makine bakÄ±m planlamasÄ± nasÄ±l yapÄ±lÄ±r?",
                "Tedarik zinciri yÃ¶netimi stratejileri",
                "Ãœretim maliyetlerini nasÄ±l dÃ¼ÅŸÃ¼rebilirim?",
                "Ä°ÅŸ gÃ¼venliÄŸi Ã¶nlemleri nelerdir?",
                "Ã‡evre dostu Ã¼retim nasÄ±l yapÄ±lÄ±r?",
                "Otomasyon sÃ¼reÃ§leri nasÄ±l planlanÄ±r?",
            ],
            "tourism_hospitality": [
                "Otel rezervasyonu nasÄ±l yapÄ±lÄ±r?",
                "Restoran menÃ¼sÃ¼nde neler var?",
                "Tur rehberi hizmetleri nelerdir?",
                "HavalimanÄ± transfer hizmeti var mÄ±?",
                "Oda servisi saatleri nelerdir?",
                "Spa ve wellness hizmetleri nelerdir?",
                "Konferans salonu kiralama Ã¼creti nedir?",
                "Ã–zel etkinlik organizasyonu yapÄ±lÄ±yor mu?",
            ],
            "energy": [
                "Elektrik faturasÄ± nasÄ±l Ã¶denir?",
                "DoÄŸalgaz kesintisi ne zaman sona erecek?",
                "GÃ¼neÅŸ enerjisi kurulum maliyeti nedir?",
                "Enerji tasarrufu Ã¶nerileri nelerdir?",
                "Elektrik arÄ±za bildirimi nasÄ±l yapÄ±lÄ±r?",
                "Yenilenebilir enerji teÅŸvikleri nelerdir?",
                "Enerji verimliliÄŸi danÄ±ÅŸmanlÄ±ÄŸÄ± var mÄ±?",
                "AkÄ±llÄ± sayaÃ§ kurulumu nasÄ±l yapÄ±lÄ±r?",
            ],
        }

    def on_start(self):
        """KullanÄ±cÄ± baÅŸladÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lÄ±r."""
        logger.info(f"KullanÄ±cÄ± {self.client.base_url} baÅŸladÄ±")
        self._log_system_info()

    def _log_system_info(self):
        """Sistem bilgilerini logla."""
        try:
            # CPU ve RAM bilgileri
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()

            # GPU bilgileri (varsa)
            gpu_info = "GPU bilgisi bulunamadÄ±"
            try:
                gpus = GPUtil.getGPUs()
                if gpus:
                    gpu_info = f"GPU: {gpus[0].name}, Memory: {gpus[0].memoryUsed}MB/{gpus[0].memoryTotal}MB"
            except:
                pass

            logger.info(
                f"Sistem Bilgileri - CPU: {cpu_percent}%, RAM: {memory.percent}%, {gpu_info}"
            )

        except Exception as e:
            logger.warning(f"Sistem bilgileri alÄ±namadÄ±: {e}")

    @task(3)
    def test_sector_specific_query(self):
        """SektÃ¶re Ã¶zel sorgu testi - %75 aÄŸÄ±rlÄ±k."""
        # AÄŸÄ±rlÄ±klara gÃ¶re sektÃ¶r seÃ§
        sector = self._select_sector_by_weight()
        queries = self.sector_queries.get(sector, [])

        if not queries:
            logger.warning(f"{sector} iÃ§in sorgu bulunamadÄ±")
            return

        query = random.choice(queries)

        # Router endpoint'ini test et
        start_time = time.time()

        try:
            response = self.client.post("/classify", json={"text": query})

            if response.status_code == 200:
                result = response.json()
                latency = (time.time() - start_time) * 1000  # ms cinsinden

                # Metrikleri gÃ¼ncelle
                self.benchmark_metrics["total_requests"] += 1
                self.benchmark_metrics["successful_requests"] += 1
                self.benchmark_metrics["latencies"].append(latency)
                self.benchmark_metrics["sector_distribution"][sector] += 1
                self.benchmark_metrics["response_sizes"].append(len(response.content))

                # BaÅŸarÄ±lÄ± yanÄ±t kontrolÃ¼
                if result.get("sector") == sector:
                    logger.info(
                        f"âœ… {sector}: DoÄŸru sÄ±nÄ±flandÄ±rma, Gecikme: {latency:.2f}ms"
                    )
                else:
                    logger.warning(
                        f"âš ï¸ {sector}: YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rma, Beklenen: {sector}, AlÄ±nan: {result.get('sector')}"
                    )

            else:
                self.benchmark_metrics["failed_requests"] += 1
                self.benchmark_metrics["error_types"][
                    f"HTTP_{response.status_code}"
                ] += 1
                logger.error(f"âŒ {sector}: HTTP {response.status_code} hatasÄ±")

        except Exception as e:
            self.benchmark_metrics["failed_requests"] += 1
            self.benchmark_metrics["error_types"][str(type(e).__name__)] += 1
            logger.error(f"âŒ {sector}: Ä°stek hatasÄ±: {e}")

    def _select_sector_by_weight(self) -> str:
        """AÄŸÄ±rlÄ±klara gÃ¶re sektÃ¶r seÃ§."""
        sectors = list(self.sector_weights.keys())
        weights = list(self.sector_weights.values())
        return random.choices(sectors, weights=weights, k=1)[0]

    @task(1)
    def test_general_query(self):
        """Genel sorgu testi - %25 aÄŸÄ±rlÄ±k."""
        general_queries = [
            "Merhaba, nasÄ±lsÄ±nÄ±z?",
            "BugÃ¼n hava nasÄ±l?",
            "TÃ¼rkiye'nin baÅŸkenti neresidir?",
            "Matematik problemlerini nasÄ±l Ã§Ã¶zebilirim?",
            "Yemek tarifi arÄ±yorum",
            "Spor mÃ¼sabakasÄ± sonuÃ§larÄ± neler?",
            "Kitap Ã¶nerisi istiyorum",
            "MÃ¼zik tÃ¼rleri hakkÄ±nda bilgi verir misiniz?",
        ]

        query = random.choice(general_queries)
        start_time = time.time()

        try:
            response = self.client.post(
                "/infer", json={"text": query, "max_length": 150, "temperature": 0.7}
            )

            if response.status_code == 200:
                result = response.json()
                latency = (time.time() - start_time) * 1000

                self.benchmark_metrics["total_requests"] += 1
                self.benchmark_metrics["successful_requests"] += 1
                self.benchmark_metrics["latencies"].append(latency)
                self.benchmark_metrics["sector_distribution"]["general"] += 1
                self.benchmark_metrics["response_sizes"].append(len(response.content))

                logger.info(f"âœ… Genel sorgu: YanÄ±t alÄ±ndÄ±, Gecikme: {latency:.2f}ms")

            else:
                self.benchmark_metrics["failed_requests"] += 1
                self.benchmark_metrics["error_types"][
                    f"HTTP_{response.status_code}"
                ] += 1
                logger.error(f"âŒ Genel sorgu: HTTP {response.status_code} hatasÄ±")

        except Exception as e:
            self.benchmark_metrics["failed_requests"] += 1
            self.benchmark_metrics["error_types"][str(type(e).__name__)] += 1
            logger.error(f"âŒ Genel sorgu hatasÄ±: {e}")

    @task(1)
    def test_router_endpoint(self):
        """Router endpoint testi."""
        test_texts = [
            "Banka kredisi almak istiyorum",
            "Hastane randevusu almak istiyorum",
            "Ãœniversite sÄ±navÄ±na hazÄ±rlanÄ±yorum",
            "E-ticaret sitesi kurmak istiyorum",
            "Fabrikada Ã¼retim sÃ¼reÃ§lerini optimize etmek istiyorum",
        ]

        text = random.choice(test_texts)
        start_time = time.time()

        try:
            response = self.client.post("/classify", json={"text": text})

            if response.status_code == 200:
                result = response.json()
                latency = (time.time() - start_time) * 1000

                self.benchmark_metrics["total_requests"] += 1
                self.benchmark_metrics["successful_requests"] += 1
                self.benchmark_metrics["latencies"].append(latency)
                self.benchmark_metrics["response_sizes"].append(len(response.content))

                logger.info(
                    f"âœ… Router test: {result.get('sector')}, Gecikme: {latency:.2f}ms"
                )

            else:
                self.benchmark_metrics["failed_requests"] += 1
                self.benchmark_metrics["error_types"][
                    f"HTTP_{response.status_code}"
                ] += 1
                logger.error(f"âŒ Router test: HTTP {response.status_code} hatasÄ±")

        except Exception as e:
            self.benchmark_metrics["failed_requests"] += 1
            self.benchmark_metrics["error_types"][str(type(e).__name__)] += 1
            logger.error(f"âŒ Router test hatasÄ±: {e}")

    def on_stop(self):
        """KullanÄ±cÄ± durduÄŸunda Ã§aÄŸrÄ±lÄ±r."""
        logger.info(f"KullanÄ±cÄ± {self.client.base_url} durdu")
        self._log_metrics()

    def _log_metrics(self):
        """Metrikleri logla."""
        if self.benchmark_metrics["total_requests"] > 0:
            success_rate = (
                self.benchmark_metrics["successful_requests"]
                / self.benchmark_metrics["total_requests"]
            ) * 100
            avg_latency = (
                np.mean(self.benchmark_metrics["latencies"])
                if self.benchmark_metrics["latencies"]
                else 0
            )

            logger.info(
                f"ğŸ“Š Metrikler - Toplam: {self.benchmark_metrics['total_requests']}, "
                f"BaÅŸarÄ±: {success_rate:.1f}%, Ortalama Gecikme: {avg_latency:.2f}ms"
            )


class BenchmarkReporter:
    """Benchmark sonuÃ§larÄ±nÄ± raporlayan sÄ±nÄ±f."""

    def __init__(self):
        self.metrics = defaultdict(list)
        self.start_time = time.time()

    def on_request_success(self, request_type, name, response_time, response_length):
        """BaÅŸarÄ±lÄ± istek metriklerini kaydet."""
        self.metrics["successful_requests"].append(
            {
                "type": request_type,
                "name": name,
                "response_time": response_time,
                "response_length": response_length,
                "timestamp": time.time(),
            }
        )

    def on_request_failure(self, request_type, name, response_time, exception):
        """BaÅŸarÄ±sÄ±z istek metriklerini kaydet."""
        self.metrics["failed_requests"].append(
            {
                "type": request_type,
                "name": name,
                "response_time": response_time,
                "exception": str(exception),
                "timestamp": time.time(),
            }
        )

    def generate_report(self) -> Dict:
        """Benchmark raporu oluÅŸtur."""
        end_time = time.time()
        duration = end_time - self.start_time

        successful = self.metrics["successful_requests"]
        failed = self.metrics["failed_requests"]

        if successful:
            response_times = [req["response_time"] for req in successful]
            avg_response_time = np.mean(response_times)
            p95_response_time = np.percentile(response_times, 95)
            p99_response_time = np.percentile(response_times, 99)
        else:
            avg_response_time = p95_response_time = p99_response_time = 0

        return {
            "test_duration_seconds": duration,
            "total_requests": len(successful) + len(failed),
            "successful_requests": len(successful),
            "failed_requests": len(failed),
            "success_rate_percent": (
                (len(successful) / (len(successful) + len(failed))) * 100
                if (len(successful) + len(failed)) > 0
                else 0
            ),
            "avg_response_time_ms": avg_response_time,
            "p95_response_time_ms": p95_response_time,
            "p99_response_time_ms": p99_response_time,
            "requests_per_second": (
                (len(successful) + len(failed)) / duration if duration > 0 else 0
            ),
            "error_summary": (
                dict(Counter([req["exception"] for req in failed])) if failed else {}
            ),
        }


# Global reporter instance
reporter = BenchmarkReporter()


@events.request.add_listener
def on_request_success(request_type, name, response_time, response_length, **kwargs):
    """BaÅŸarÄ±lÄ± istek event listener'Ä±."""
    reporter.on_request_success(request_type, name, response_time, response_length)


@events.request.add_listener
def on_request_failure(request_type, name, response_time, exception, **kwargs):
    """BaÅŸarÄ±sÄ±z istek event listener'Ä±."""
    reporter.on_request_failure(request_type, name, response_time, exception)


@events.test_stop.add_listener
def on_test_stop(environment, **kwargs):
    """Test durduÄŸunda final raporu oluÅŸtur."""
    report = reporter.generate_report()

    # Raporu dosyaya kaydet
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    report_file = f"benchmark_results/locust_report_{timestamp}.json"

    os.makedirs("benchmark_results", exist_ok=True)

    with open(report_file, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    logger.info(f"ğŸ“Š Benchmark raporu kaydedildi: {report_file}")
    logger.info(
        f"ğŸ“ˆ Test SonuÃ§larÄ±: {report['successful_requests']} baÅŸarÄ±lÄ±, "
        f"{report['failed_requests']} baÅŸarÄ±sÄ±z, "
        f"Ortalama gecikme: {report['avg_response_time_ms']:.2f}ms"
    )
